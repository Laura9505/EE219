EE219 Winter 2018 Project 5

Team:
    Qidi Sang - 705028670
    Hui Wang - 205036597
    Zhonglin Zhang - 005030520

Packages we used:
    json, numpy, matplotlib, sklearn, graphviz, pandas, pytz, datetime, time, statsmodels.api, nltk, re, csv, string, itertools, math

How to run the code:

==================================== Part 1/3 =======================================
    The following instructions are for windows pc. Running on other OS hasn't been tested.

    Run cmd.exe as administrator.
    Set path to current .py files folder.
    Type "python 1_1.py" to run part 1.1 of the project.
    Type "python 1_2.py" to run part 1.2 of the project.
    Type "python 1_3.py" to run part 1.3 of the project.
    Type "python 1_4.py" to run part 1.4 of the project. Note that the last 2 blocks of code have been commented, because creating aggregated data would take much time. 
                                                         If you want to run part2 of question 4, just uncomment them.  
    Type "python 1_5.py" to run part 1.5 of the project. This code uses another way to create aggregated data. 
                                                         You should first cd to .\tweet_data and run command 'type *.txt >>.\train_merge.txt' before running this code.
    Those 4 .py codes of part 2 seem to have some decoding problem in windows OS, thus we use OS X to run those codes. Please see below for detailed instructions.                                                
    Type "python 3.py" to run part 3 of the project.
    You may need Anaconda to execute code correctly.
    
    Note: You may need to close figure windows to let the program continue running.
          Please put the code and file folder 'tweet_data' and 'test_data' in the same file folder.


==================================== Part 2 =======================================
    
The programs of Part 2 are operated with PyCharm (2017.3.4) in the macOS system (Version 10.13.3). 
The interpreter is Python 3.6.
    
To run the codes, open the four scripts, which are:
    
* File 1: 2_1_TextFilter.py  
    
* File 2: 2_2_DataMatrix.py
    
* File 3: 2_3_BestPar.py
    
* File 4: 2_4_Predict.py
    
successively in PyCharm and press "Run..." to run the codes directly.  
    
Their main functions are:
    
File 1: Select the tweets from MA and WA states and store them into a csv file.
    
File 2: Strip stop words, use stemmed words to generate sparse matrix and also save them in csv files.
    
File 3: Select the best parameters for different learning models.
    
File 4: For best parameters, report their classification performance.

    
* Note:
    
1. The four scripts should be run in sequence because the latter files will use the files generated by the former ones.
    
2. All the data sheet will be save directly in the current directory while all the plots will be saved in the ./pics folder.
    
3. The codes of Part 2 will report errors when run in the Windows system. 
    
